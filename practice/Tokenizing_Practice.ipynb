{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tokenizing_Practice.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOKtAWjBA2E/eBbw3X2Bgin"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fN2Stl7I2hMd","executionInfo":{"status":"ok","timestamp":1656298690189,"user_tz":240,"elapsed":30760,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}},"outputId":"1789ca36-e5bf-4cad-b137-c48eb6f03754"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Co\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpad.net\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpad.net\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,521 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,866 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,297 kB]\n","Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,013 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,298 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,047 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,026 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n","Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,037 kB]\n","Fetched 15.4 MB in 6s (2,606 kB/s)\n","Reading package lists... Done\n"]}],"source":["import os\n","# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.3'\n","spark_version = 'spark-3.0.3'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"]},{"cell_type":"code","source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"metadata":{"id":"1ahz8nK7F8nj","executionInfo":{"status":"ok","timestamp":1656298716378,"user_tz":240,"elapsed":8691,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[" #Create a sample dataframe:\n"," df = spark.createDataFrame([\n","    (0, \"Spark is great\"),\n","    (1, \"We are learning Spark\"),\n","    (2, \"Spark is better than Hadoop no doubt\"),\n"," ], [\"id\",\"sentence\"])\n"," df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bo-8vsJ8GZwf","executionInfo":{"status":"ok","timestamp":1656298954488,"user_tz":240,"elapsed":5194,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}},"outputId":"9ae3ca41-ddf8-44cf-a5b8-7a8a50a0fc9d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.ml.feature import Tokenizer\n","# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer\n","# Transform DataFrame\n","tokenized_df = tokenizer.transform(df)\n","tokenized_df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sunL11_F-gr","executionInfo":{"status":"ok","timestamp":1656299037342,"user_tz":240,"elapsed":1071,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}},"outputId":"3affd185-c5b0-4edc-9ab7-f5eb28c6043a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["# Create a function to return the length of a list\n","def word_list_length(word_list):\n","    return len(word_list)"],"metadata":{"id":"LZo7EekrGB7L","executionInfo":{"status":"ok","timestamp":1656299047237,"user_tz":240,"elapsed":157,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType\n","# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"metadata":{"id":"70tLNUoqGDNu","executionInfo":{"status":"ok","timestamp":1656299065710,"user_tz":240,"elapsed":144,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Select the needed columns and DONT truncate the results\n","tokenized_df.withColumn('tokens', count_tokens(col('words'))).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTpeP6OIHi6R","executionInfo":{"status":"ok","timestamp":1656299192018,"user_tz":240,"elapsed":1194,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}},"outputId":"1c5ca168-795f-40e8-fd3b-2b6919646ecb"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"]}]},{"cell_type":"code","source":["# Import stop words library\n","from pyspark.ml.feature import StopWordsRemover"],"metadata":{"id":"It4CvXlHH_jr","executionInfo":{"status":"ok","timestamp":1656299234397,"user_tz":240,"elapsed":157,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Run the Remover\n","remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"],"metadata":{"id":"iYmc3ofuIKKZ","executionInfo":{"status":"ok","timestamp":1656299379273,"user_tz":240,"elapsed":173,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["remover.transform(tokenized_df).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Abwgw6EvIRjC","executionInfo":{"status":"ok","timestamp":1656299386270,"user_tz":240,"elapsed":687,"user":{"displayName":"Michael Pournaras","userId":"16128872665399997452"}},"outputId":"8f9d94e9-9479-4ec7-8b08-9b869cce2c64"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+------------------------------------+--------------------------------------------+------------------------------+\n","|id |sentence                            |words                                       |filtered                      |\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |[spark, great]                |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |[learning, spark]             |\n","|2  |Spark is better than Hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|[spark, better, hadoop, doubt]|\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"AGLD2gPnIdO6"},"execution_count":null,"outputs":[]}]}